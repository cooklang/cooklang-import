#!/usr/bin/env python3

import argparse
import re
import sys

from recipe_scrapers import scrape_me, WebsiteNotImplementedError
from parse_ingredients import parse_ingredient

from utils import eprint, sub_lists, print_recipe, highlight_replacement_in_text


parser = argparse.ArgumentParser(
    description="Automatically extract recipes from online websites."
)
parser.add_argument("-l","--link", help="Input a url link to a recipe")
parser.add_argument(
    "-f",
    "--file",
    help="If you want the output to be in a file, use this flag. Otherwise defaults to console screen.",
    action="store_true",
)
args = parser.parse_args()

# Check if no arguments are passed
if len(sys.argv) == 1:
    parser.print_help()
    sys.exit()

# give the url as a string, it can be url from any site listed below
try:
    scraper = scrape_me(args.link)
except WebsiteNotImplementedError as e:
    print("The domain is currently not supported, %s. You can request adding this domain at https://github.com/hhursev/recipe-scrapers." % e.domain)
    sys.exit(1)
  
# Q: What if the recipe site I want to extract information from is not listed below?
# A: You can give it a try with the wild_mode option! If there is Schema/Recipe available it will work just fine.
# scraper = scrape_me('https://www.feastingathome.com/tomato-risotto/', wild_mode=True)

title = scraper.title()
image = scraper.image()
total_time = scraper.total_time()

eprint("Title:", title)
eprint("Image:", image)

instructions = scraper.instructions()
# Remove those pesky punctuation
ingredients_list = [
    parse_ingredient(re.sub(r"\.", "", ingredient))
    for ingredient in scraper.ingredients()
]

# Convert the timers
time_regex_match_str = r"(\d+|\d+\.\d+|\d+-\d+|\d+ to \d+) (min(?:utes)?|hours?|days?)"
instructions = re.sub(time_regex_match_str, r"~{\1%\2}", instructions)

for combined_ingredient in ingredients_list:

    quantity = combined_ingredient.quantity
    unit = combined_ingredient.unit

    # remove extra characters aka ')'
    ingredient_fixed = re.sub(r" ?\)", "", combined_ingredient.name)

    # Create sublists for word matches
    # Idea is to greedly match as many words as possible
    ing_list = sub_lists(ingredient_fixed.split(" "))

    # Filter out empty sublist
    ing_list = list(filter(lambda x: len(x) > 0, ing_list))

    # Remove single stop words
    ing_list = list(
        filter(lambda x: x[0] not in {"and", "or", "for", "the", "of"}, ing_list)
    )

    # Now generate regex string to  match
    ing_list = sorted(ing_list, reverse=True, key=lambda x: len(x))
    ing_regex_match_str = "|".join(list(map(lambda x: fr'\b{" ".join(x)}\b', ing_list)))
    ing_regex_match_str = "(?:[^@])(" + ing_regex_match_str + ")"
    # regex match the text
    match_obj = re.search(ing_regex_match_str, instructions, flags=re.I)

    eprint("")
    eprint(
        "✅" if match_obj is not None else "❌",
        f"@{combined_ingredient.name}{{{quantity:.0f}%{unit}}}" if unit != "" else f"@{combined_ingredient.name}{{{quantity:.0f}}}"
    )

    # If no match skip ingredient
    if match_obj is None:
        continue

    match_start = match_obj.start(1)
    match_end = match_obj.end(1)

    highlight_replacement_in_text(instructions, match_start, match_end)

    ing_replacement = f"@{match_obj[1]}{{{quantity:.0f}%{unit}}}" if unit != "" else f"@{match_obj[1]}{{{quantity:.0f}}}"
    instructions = (
        instructions[0:match_start]
        + ing_replacement
        + instructions[match_obj.end() :]
    )


instructions = instructions.replace("\n", "\n\n")

print_recipe(title, args.link, total_time, image, instructions, to_file=args.file)
